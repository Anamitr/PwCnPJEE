VB 6.1  Vagrant 2.2.7
VB 6.0  Vagran 2.2.5
HADOOP_VERSION = 2.6.4
vagrant plugin install vagrant-vbguest

W vagrant file cpu dac 1. Pamieci zalezy ile mamy w komputerze. Pamieci bezpiecznie 2GB na mastera, na 2 slavy po 1.
files - pliki do skopiowania
shells - skrypty ktore sie uruchomia po wstaniu maszyny

vagrant up                                      - uruchamia wszystkie 3 naraz
vagrant up hadoop-master                        - uruchamiamy tylko hadoop-master
vagrant ssh hadoop-master                       - logowanie
cd scripts && sh jps.sh                         - powinno wypisac jednego mastera i dwa slavy

W dokumentacji na Hadoopie wpisac w linku 2.6.4
Opcjonalnie ustawic single-node
Przeczytac general cluster setup

Uzupleniajac pliki xml nie trzeba dopisywac nowych wartosci, tylko uzupelnic value dla tych ktore sa.
localhost:50070 - overview hadoop

W plikach master i slaves wpisac numery ip albo nazwy tychze.


Notes
- to poweroff virtual machines use "vagrant halt", to turn them on "vagrant up" (the same as creating)
- use mvn from this system, not virtual machine
- to build project with maven and generate .jar use "mvn install" command
- before starting calculation with hadoop, you have to start it with demo.sh (or start.sh or sth like that)
- put files with "hadoop fs -put file destination"
- move/remove file input/hadoop or it won't work (or put input files in another folder)
- run program with "hadoop jar jar_name class_to_run input_folder output_folder"
- print output with "hadoop fs -cat output_dir/*"
- to delete folder and its files use "hadoop fs -rm -R URI"

hadoop_multi_node_3 - freshest

https://hadoop.apache.org/docs/r2.6.4/hadoop-project-dist/hadoop-common/ClusterSetup.html
https://hadoop.apache.org/docs/r2.6.4/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
Paremeters:
fs.default.name                 - adres hdfs, systemu plików hadoopa
dfs.webhdfs.enabled             - właczenie REST API do obsługi hadoopa
dfs.namenode.rpc-address        - podane przez prowadzącego, adres do obsługi klientów?
dfs.replication                 - number of file replications
mapreduce.framework.name        - https://mapr.com/docs/61/ReferenceGuide/mapred-site.xml.html
yarn.resourcemanager.hostname   - "host" from docs
yarn.nodemanager.aux-services   - "shuffle service that needs to be set for Map Reduce applications." from docs
